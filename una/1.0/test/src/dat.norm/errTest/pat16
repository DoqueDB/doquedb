  視線入力精度を高め、しかも、裸眼の観察者と眼鏡を装着した観察者の何れに対して、同等の視線入力を可能にする。  眼鏡のレンズ情報を検出する眼鏡レンズ情報検出手段１００と、検出された眼鏡レンズ情報を記憶する記憶手段１００ａと、観察者が眼鏡を装着している場合は、受光手段１４，１０１にて得られた眼球像データと記憶手段に記憶された眼鏡レンズ情報から観察者の視線を演算する視線演算手段１００を備え、一度眼鏡レンズ情報（眼鏡レンズの曲率半径，曲率中心位置）を検出した後は記憶手段に記憶しておき、必要に応じて前記記憶手段より眼鏡レンズ情報を読出し、該眼鏡レンズ情報と受光手段にて得られた眼球像データとから、観察者の視線を算出するようにしている。  観察者の眼球を照明する照明手段と、観察者の眼球にて反射された光を受光する受光手段と、観察者が眼鏡を装着しているか否かを検知する眼鏡検知手段と、眼鏡のレンズ情報を検出する眼鏡レンズ情報検出手段と、検出された眼鏡レンズ情報を記憶する記憶手段と、前記眼鏡検知手段にて観察者が眼鏡を装着していることが検知されている場合は、前記受光手段にて得られた眼球像データと前記記憶手段に記憶された眼鏡レンズ情報から観察者の視線を演算する視線演算手段とを備えた光学装置。  前記眼鏡レンズ情報は、眼鏡レンズの曲率半径と曲率中心位置のうちの少なくとも曲率半径であることを特徴とする請求項１記載の光学装置。  設定可能な、観察者の視線により情報を入力する視線入力モードと観察者の視線の個人差を補正する為の視線キャリブレーションデータを取得する視線キャリブレーションモードのうち、視線キャリブレーションモード時に、前記眼鏡レンズ情報検出手段は作動する手段であることを特徴とする請求項１又は２記載の光学装置。  前記照明手段は、裸眼観察者用の少なくとも２個の光源と眼鏡観察者用の少なくとも２個の光源とから成り、眼鏡レンズ情報検出時には、上記の各光源を使用することを特徴とする請求項１，２又は３記載の光学装置。  前記照明手段は、裸眼観察者用の光源を３個以上具備しており、眼鏡レンズ情報検出時には、該３個以上の裸眼観察者用の光源を使用することを特徴とする請求項１，２又は３記載の光学装置。  眼鏡レンズ情報検出時には、この際に用いる照明用光源の照明輝度の低減と照明用光源と同期した受光手段の一部であるイメージセンサの蓄積時間の短縮の少なくとも一方を行うことを特徴とする請求項４又は５記載の光学装置。  前記視線演算手段は、観察者の眼球と該装置との相対変位が所定値以上の場合に、前記記憶手段に記憶された眼鏡レンズ情報に基づいて観察者の視線を補正演算する手段であることを特徴とする請求項１記載の光学装置。  観察者の眼球を照明する照明手段と、観察者の眼球にて反射された光を受光する受光手段と、観察者が眼鏡を装着しているか否かを検知する眼鏡検知手段と、眼鏡のレンズ情報を検出する眼鏡レンズ情報検出手段と、前記眼鏡検知手段にて観察者が眼鏡を装着していることが検知されている場合は、前記受光手段にて得られた眼球像データと前記眼鏡レンズ情報検出手段にて得られた眼鏡レンズ情報から観察者の視線を検出する視線検出手段とを備えた光学装置。  前記眼鏡レンズ情報は、眼鏡レンズの曲率半径と曲率中心位置のうちの少なくとも曲率半径であることを特徴とする請求項８記載の光学装置。  前記照明手段は、裸眼観察者用の少なくとも２個の光源と眼鏡観察者用の少なくとも２個の光源とから成り、眼鏡レンズ情報検出時には、上記の各光源を使用することを特徴とする請求項８又は９記載の光学装置。  前記照明手段は、裸眼観察者用の光源を３個以上具備しており、眼鏡レンズ情報検出時には、該３個以上の裸眼観察者用の光源を使用することを特徴とする請求項８又は９記載の光学装置。  眼鏡レンズ情報検出時には、この際に用いる照明用光源の照明輝度の低減と照明用光源と同期した受光手段の一部であるイメージセンサの蓄積時間の短縮の少なくとも一方を行うことを特徴とする請求項１０又は１１記載の光学装置。  前記視線検出手段は、観察者の眼球と該装置との相対変位が所定値以上の場合に、前記眼鏡レンズ情報に基づいて観察者の視線を補正演算する手段であることを特徴とする請求項８記載の光学装置。  観察者の眼球を照明する照明手段と、観察者の眼球にて反射された光を受光する受光手段と、観察者が眼鏡を装着している場合は、前記眼鏡のレンズの曲率半径を用いて、前記受光手段にて得られた眼球像データの歪を補正して視線を検出する視線検出手段とを備えた光学装置。  上記の請求項１，８又は１４記載の光学装置を備えたことを特徴とするカメラ。本発明は、観察者の視線を算出する手段を有した光学装置や該装置を具備したカメラの改良に関するものである。従来より、観察者が観察面上のどの位置を観察しているかを検出する、いわゆる視線を検出する装置（例えばアイカメラ）が種々提供されている。本願出願人は、特開平２−２６４６３２号公報において、観察者の眼球に赤外光を照射し、眼球の角膜からの反射光による角膜反射像と瞳孔の結像位置を利用して観察者の視線を求める視線検出装置を開示している。図１１は公知の視線検出方法の原理説明図である。同図において、１３ａ，１３ｂは各々観察者に対して不感の赤外光を放射する発光ダイオード等の光源であり、各々の光源１３ａ，１３ｂは受光レンズ１２の光軸に対してｘ方向に略対象に配置され観察者の眼球１５を発散照射している。同図において明かではないが、光源１３ａ，１３ｂは観察者の眼球１５を下方（ｙ方向にオフセットした位置）から照明するように配置されている。眼球１５で反射した照明光の一部は受光レンズ１２を介してイメージセンサ１４に集光する。１６は角膜、１７は虹彩である。図１２（Ａ）は上記イメージセンサ１４に投影される眼球像の概略図であり、図１２（Ｂ）は上記イメージセンサ１４の出力ラインからの信号の強度分布を示す図である。以下、上記の各図を用いて視線の検出方法について説明する。光源１３ａより放射された赤外光は観察者の眼球１５の角膜１６を照射する。このとき角膜１６の表面で反射した赤外光の一部により形成される角膜反射像ｄ（虚像）は受光レンズ１２により集光され、イメージセンサ１４上の位置ｄ´に結像する。同様に光源１３ｂにより放射された赤外光は、眼球１５の角膜１６を照明する。このとき、角膜１６の表面で反射した赤外光の一部により形成された角膜反射像ｅは受光レンズ１２により集光され、イメージセンサ１４上の位置ｅ´に結像する。又、虹彩１７の端部ａ，ｂからの光束は、受光レンズ１２を介してイメージセンサ１４上の位置ａ´，ｂ´に該端部ａ，ｂの像を結像する。受光レンズ１２の光軸に対する眼球１５の光軸の回転角θが小さい場合、虹彩１７の端部ａ，ｂのｘ座標をｘａ，ｘｂとすると、瞳孔１９の中心位置ｃの座標ｘｃは、ｘｃ≒（ｘａ＋ｘｂ）／２と表される。また、角膜反射像ｄ及びｅの中点のｘ座標と角膜１６の曲率中心ｏのｘ座標ｘｏとは略一致する。このため角膜反射像の発生位置ｄ，ｅのｘ座標をｘｄ，ｘｅ、角膜１６の曲率中心ｏと瞳孔１９の中心ｃまでの標準的な距離をＬOCとすると、眼球１５の光軸１５ａの回転角θｘは、    ＬOC＊ｓｉｎθｘ≒（ｘｄ＋ｘｅ）／２−ｘｃ          …………（１）の関係式を略満足する。このため、図１２（Ａ）に示した様に、メージセンサ１４上に投影された眼球１５の各特徴点（角膜反射像及び瞳孔の中心）の位置を検出することにより、眼球１５の光軸１５ａの回転角θを求めることができる。眼球１５の光軸１５ａの回転角は（１）式より、    β＊ＬOC＊ｓｉｎθｘ≒｛（ｘｐｏ−δｘ）−ｘｉｃ｝＊ｐｉｔｃｈ                                                        …………（２）    β＊ＬOC＊ｓｉｎθｙ≒｛（ｙｐｏ−δｙ）−ｙｉｃ｝＊ｐｉｔｃｈ                                                        …………（３）と求められる。ここで、θｘはｚーｘ平面内での眼球光軸の回転角、θｙはｙーｚ平面内での眼球光軸の回転角である。また、（ｘｐｏ，ｙｐｏ）はイメージセンサ１４上の２個の角膜反射像の中点の座標、（ｘｉｃ，ｙｉｃ）はイメージセンサ１４上の瞳孔中心の座標である。ｐｉｔｃｈはイメージセンサ１４の画素ピッチである。又、βは受光レンズ１２に対する眼球１５の位置により決る結像倍率で、実質的には２個の角膜反射像の間隔の関数として求められる。δｘ，δｙは角膜反射像の中点の座標を補正する補正項であり、撮影者の眼球を平行光ではなく発散光にて照明していることにより生じる誤差を補正する補正項、及び、δｙに関しては、撮影者の眼球を下まぶたの方から発散光にて照明していることにより生じるオフセット成分を補正する補正項も含まれている。該補正項の式は、特開平２−２６４６３３号公報に開示されている。観察者の眼球光軸１５ａの回転角（θｘ，θｙ）が算出されると、観察者の観察面上の注視点（ｘ，ｙ）は、例えば、    ｘ＝ｍ＊｛θｘ−（ｃｘ＊Ｒｐ＋ｄｘ）｝                  ／（ａｘ＊Ｒｐ＋ｂｘ）                …………（４）    ｙ＝ｍ＊｛θｙ−（ｃｙ＊Ｒｐ＋ｄｙ）｝                  ／（ａｙ＊Ｒｐ＋ｂｙ）                …………（５）と求められる。ここで、ｘ方向は観察者に対して水平方向、ｙ方向は観察者に対して垂直方向を示している。ｍは眼球１５の回転角から観察面上の座標に変換する変換係数、Ｒｐは瞳孔径である。また、ａｘ，ｂｘ，ｃｘ，ｄｘ，ａｙ，ｂｙ，ｃｙ，ｄｙは注視点キャリブレーション係数で、観察者の眼球１５の回転角と観察面上の注視点を一致させるための補正係数である。また、本願出願人は、特開平４−１３８４３１号，特開平４−１３８４３２号公報において、観察者が眼鏡を装着しているか否かを検知可能な視線検出手段を有した装置を開示している。該提案装置の実施例によれば、観察者が眼鏡を装着していることを検知すた場合は、受光光学系等を位置調整を行って良好な視線検出を達成しようとしている。しかしながら、観察者が眼鏡を装着しているとイメージセンサ上に生成される角膜反射像及び虹彩像の位置が眼鏡レンズの屈折作用によってずれてしまう（像歪み）場合があり、このような場合には従来の視線演算方法では精度の高い視線検出ができないという問題点があった。また、特開平５−１００１４７号公報において、観察者が眼鏡を装着していることを検知することにより、視線検出結果を補正、又は、無効化する補正手段を含む視線検出装置を有するカメラが開示されているが、該補正手段は眼鏡を装着した観察者に対してカメラの機能を制限（画面中央の領域に限定したり、無効にすることで）して制御しようとするもので、該観察者はカメラの使用に際しカメラの機能を十分に使えず不都合を感じるという問題点があった。（発明の目的）本発明の目的は、高精度であり、しかも、裸眼の観察者と眼鏡を装着した観察者の何れに対して、同等の視線入力を可能とする光学装置及びカメラを提供することである。上記の目的を達成するために、請求項１又は１５記載の本発明は、眼鏡のレンズ情報を検出する眼鏡レンズ情報検出手段と、検出された眼鏡レンズ情報を記憶する記憶手段と、観察者が眼鏡を装着している場合は、受光手段にて得られた眼球像データと前記記憶手段に記憶された眼鏡レンズ情報から観察者の視線を演算する視線演算手段とを備え、一度眼鏡レンズ情報を検出した後は記憶手段に記憶しておき、必要に応じて前記記憶手段より眼鏡レンズ情報を読出し、該眼鏡レンズ情報と受光手段にて得られた眼球像データとから、観察者の視線を算出するようにしている。また、請求項８又は１５記載の本発明は、観察者が眼鏡を装着している場合は、眼鏡のレンズ情報を検出する眼鏡レンズ情報検出手段と、観察者が眼鏡を装着している場合は、受光手段にて得られた眼球像データと前記眼鏡レンズ情報検出手段にて得られた眼鏡レンズ情報から観察者の視線を検出する視線検出手段とを備え、観察者が眼鏡を装着している場合は、毎回眼鏡レンズ情報を検出し、検出した眼鏡レンズ情報と受光手段にて得られた眼球像データとから、観察者の視線を検出するようにしている。また、請求項１４又は１５記載の本発明は、観察者が眼鏡を装着している場合は、眼鏡のレンズの曲率半径を用いて、受光手段にて得られた眼球像データの歪を補正して視線を検出する視線検出手段とを備え、観察者が眼鏡を装着している場合は、受光手段にて得られた眼球像データを、眼鏡レンズの曲率半径により補正するようにしている。以下、本発明を図示の実施例に基づいて詳細に説明する。図１は本発明を一眼レフカメラに適用したときの一実施例を示す要部概略図であり、図２（Ａ），（Ｂ）は同じくその上面と後面の概略図、図３は図１のファインダ視野内の説明図である。これらの図において、１は撮影レンズで、便宜上２枚のレンズで示したが、実際はさらに多数のレンズから構成されている。２は主ミラーで、ファインダ系による被写体像の観察状態と被写体像の撮影状態に応じて撮影光路へ斜設され、或は、退去される。３はサブミラーで、主ミラー２を透過した光束をカメラボディの下方の後述する焦点検出装置６へ向けて反射する。４はシャッタ、５は感光部材で、銀塩フィルム、或は、ＣＣＤやＭＯＳ型等の固体撮像素子、或は、ビディコン等の撮像管である。６は焦点検出装置であり、結像面近傍に配置されたフィールドレンズ６ａ，反射ミラー６ｂ及び６ｃ，二次結像レンズ６ｄ，絞り６ｅ、複数のＣＣＤから成るラインセンサ６ｆ等から構成されている。本実施例における焦点検出装置６は、周知の位相差方式にて焦点検出を行うものであり、図３に示すように、観察画面内（ファインダ視野内）２１３の複数の領域（５箇所の測距点マーク２００〜２０４）を焦点検出可能となるように構成されている。７は撮影レンズ１の予定結像面に配置されたピント板、８は正立像形成光学部材であるところのペンタプリズムである。９，１０は各々観察画面内の被写体輝度を測定するための結像レンズと測光センサであり、結像レンズ９はペンタプリズム８内の反射光路を介してピント板７と測光センサ１０を共役に関係付けている。次に、ペンタプリズム８の射出後方には光分割器１１ａを備えた接眼レンズ１１が配置され、撮影者の眼１５によるピント板７の観察に使用される。光分割器１１ａは、例えば可視光を透過し赤外光を反射するダイクロイックミラーより成っている。１２は受光レンズ、１４はＣＣＤ等の光電変換素子列を二次元的に配したイメージセンサ（ＣＣＤとも記す）で、受光レンズ１２に関して所定の位置にある撮影者の眼球１５の瞳孔近傍と共役になるように配置されている。１３ａ〜１３ｈは各々撮影者の眼球１５の照明光源であるところの赤外発光ダイオード（ＩＲＥＤと記す）で、図２（Ｂ）に示すように接眼レンズ１１の回りに配置されている。ここで、ＩＲＥＤ１３ａ，１３ｂ，１３ｅ，１３ｆは裸眼の撮影者照明用であり、ゴーストの出ない位置に設けられるＩＲＥＤ１３ｃ，１３ｄ，１３ｇ，１３ｈは眼鏡を装着している撮影者照明用である。２１は明るい被写体の中でも視認できる高輝度のスーパーインポーズ用ＬＥＤで、ここから発光された光は投光用プリズム２２を介し、主ミラー２で反射されてピント板７の表示部に設けた微小プリズムアレイ７ａで垂直方向に曲げられ、ペンタプリズム８，接眼レンズ１１を通って撮影者の眼球１５に達する。そこで、ピント板７の焦点検出領域に対応する複数の位置にこの微小プリズムアレイ７ａを枠状に形成し、これを各々に対応した５つのスーパーインポーズ用ＬＥＤ２１（各々をＬＥＤ−Ｌ１，ＬＥＤ−Ｌ２，ＬＥＤ−Ｃ，ＬＥＤ−Ｒ１，ＬＥＤ−Ｒ２とする）によって照明する。これによって図３に示したファインダ視野から判かるように、各々の測距点マーク２００，２０１，２０２，２０３，２０４がファインダ視野内で光り、焦点検出領域（測距点）を表示させることができるものである（以下、これをスーパーインポーズ表示という）。２３はファインダ視野領域を形成する視野マスク、２４はファインダ視野外に撮影情報を表示するためのファインダ内ＬＣＤで、照明用ＬＥＤ（Ｆ−ＬＥＤ）２５によって照明される。このファインダ内ＬＣＤ２４を透過した光は三角プリズム２６によってファインダ視野内に導かれ、図３の２０７で示したようにファインダ視野外に表示され、撮影者は撮影情報を知ることができる。２７はカメラの姿勢を検知する水銀スイッチである。３１は撮影レンズ１内に設けた絞り、３２は後述する絞り駆動回路１１１を含む絞り駆動装置、３３はレンズ駆動用モータ、３４は駆動ギヤ等から成るレンズ駆動部材である。３５はフォトカプラで、前記レンズ駆動部材３４に連動するパルス板３６の回転を検知してレンズ焦点調節回路１１０に伝えている。焦点調節回路１１０は、この情報とカメラ側からのレンズ駆動量の情報に基づいて前記レンズ駆動用モータ３３を所定量駆動させ、撮影レンズ１を合焦位置に移動させるようになっている。３７は公知のカメラとレンズとのインターフェイスとなるマウント接点である。図２において、４１はレリーズ釦、４２は外部モニタ表示装置としてのモニタ用ＬＣＤで、予め決められたパターンを表示する固定セグメント表示部４２ａと、可変数値表示用の７セグメント表示部４２ｂとから成っている。４４はモードダイヤルで、撮影モード等の選択を行うためのものである。５５は指標である。他の操作部材については本発明とは直接関係ないので、その説明は省略する。図４は、上記図２に示したモードダイヤル４４の詳細を示す図であり、該モードダイヤル４４はカメラ本体に刻印された指標５５に表示を合せることによって、その表示内容で撮影モードが設定される。図４において、４４ａはカメラを不作動とするロックポジション、４４ｂはカメラが予め設定した撮影プログラムによって制御される自動撮影モードのポジション、４４ｃは撮影者が撮影内容を設定できるマニュアル撮影モードで、プログラムＡＥ，シャッタ優先ＡＥ，絞り優先ＡＥ，被写体深度優先ＡＥ，マニュアル露出の各撮影モードをもっている。４４ｄは後述する視線のキャリブレーションを行うキャリブレーションモードとなる「ＣＡＬ」ポジションである。再び図２に戻って、４５は電子ダイヤルで、回転してクリックパルスを発生させることによってモードダイヤル４４で選択されたモードの中でさらに選択し得る設定値を設定するためのものである。図５は上記構成の一眼レフカメラに内蔵された電気的構成を示すブロック図であり、図１と同じ部分は同一符号を付してある。カメラ本体に内蔵されたマイクロコンピュータの中央処理装置（以下、ＣＰＵと記す）１００には、ＣＣＤ読出し回路１０１，測光回路１０２，自動焦点検出回路１０３，信号入力回路１０４，ＬＣＤ駆動回路１０５，ＬＥＤ駆動回路１０６，ＩＲＥＤ駆動回路１０７，シャッタ制御回路１０８，モータ制御回路１０９が接続されている。また、撮影レンズ１内に配置された焦点調節回路１１０，絞り駆動回路１１１とは、図１で示したマウント接点３７を介して信号の伝達がなされる。ＣＰＵ１００に付随した記憶手段としてのＥＥＰＲＯＭ１００ａは、視線検出系を構成する電気部品であるところのＣＣＤ及びＩＲＥＤの位置を記憶可能である。ＣＣＤ読出し回路１０１は、イメージセンサ１４（ＣＣＤ−ＥＹＥ）からの眼球像の出力をＡ／Ｄ変換し、この像情報をＣＰＵ１００に送信する。ＣＣＤ読出し回路１０１とイメージセンサ１４は受光レンズ１２等の光学部材と併せて受光手段を構成している。ＣＰＵ１００は後述するように視線検出に必要な眼球像の各特徴点を所定のアルゴリズムに従って抽出し、さらに各特徴点の位置から撮影者の眼球の回転角を算出する。測光回路１０２は、測光センサ１０からの出力を増幅後、対数圧縮，Ａ／Ｄ変換し、各センサの輝度情報としてＣＰＵ１００に送られる。測光センサ１０は図３に示したファインダ画面内の左側測距点２００，２０１を含む左領域２１０を測光するＳＰＣ−Ｌと、中央の測距点２０２を含む中央領域２１１を測光するＳＰＣ−Ｃと、右側の測距点２０３，２０４を含む右側領域２１２を測光するＳＰＣ−Ｒと、これらの周辺領域２１３を測光するＳＰＣ−Ａとの４つのフォトダイオードから構成されている。ラインセンサ６ｆは、前述のように画面内の５つの測距点２００〜２０４に対応した５組のラインセンサＣＣＤ−Ｌ２，ＣＣＤ−Ｌ１，ＣＣＤ−Ｃ，ＣＣＤ−Ｒ１，ＣＣＤ−Ｒ２から構成される公知のＣＣＤラインセンサである。自動焦点検出回路１０３は、これらラインセンサ６ｆから得た電圧をＡ／Ｄ変換し、ＣＰＵ１００に送る。ＳＷ１はレリーズ釦４１の第１ストロークでＯＮし、測光，ＡＦ，視線検出動作を開始するスイッチ、ＳＷ２はレリーズ釦の第２ストロークでＯＮするレリーズスイッチ、ＳＷ−ＡＮＧ１，ＳＷ−ＡＮＧ２は水銀スイッチ２７及び不図示の水銀スイッチによって検知されるところの姿勢検知スイッチ、ＳＷ−ＤＩＡＬ１とＳＷ−ＤＩＡＬ２は電子ダイヤル４５内に設けたダイヤルスイッチで、信号入力回路１０４のアップダウンカウンタに入力され、電子ダイヤル４５の回転クリック量をカウントする。ＳＷ−Ｍ１〜Ｍ４はモードダイヤル内に設けたダイヤルスイッチである。これらのスイッチの信号が信号入力回路１０４に入力され、データバスによってＣＰＵ１００に送信される。液晶表示素子ＬＣＤを表示駆動させるための公知のＬＣＤ駆動回路１０５は、ＣＰＵ１００からの信号に従って絞り値，シャッタ秒時，設定した撮影モード等の表示をモニタ用ＬＣＤ４２とファインダ内ＬＣＤ２４の両方に同時に表示させている。ＬＥＤ駆動回路１０６は、照明用ＬＥＤ（Ｆ−ＬＥＤ）２２とスーパーインポーズ用ＬＥＤ２１を点灯・点滅制御する。ＩＲＥＤ駆動回路１０７は、赤外発光ダイオード（ＩＲＥＤ１〜８）１３ａ〜１３ｈを状況に応じて選択的に点灯させる。シャッタ制御回路１０８は、通電する先幕を走行させるマグネットＭＧ−１と後幕を走行させるマグネットＭＧ−２を制御し、感光部材に所定光量を露光させる。モータ制御回路１０９は、フィルムの巻上げ，巻戻しを行うモータＭ１と主ミラ及びシャッタ４のチャージを行うモータＭ２を制御している。上記のシャッタ制御回路１０８、モータ制御回路１０９によって一連のカメラのレリーズシーケンスが動作する。次に、眼鏡レンズ情報検出手段を有したカメラの動作について、図６のフローチャートにしたがって説明する。モードダイヤル４４を回転させてカメラを不作動状態（ロック状態）から所定の撮影モードに設定すると、カメラの電源がＯＮされる（ステップ１００）。すると、ＣＰＵ１００は信号入力回路１０４を介してモードダイヤル４４がどのモードに設定されているかを確認する（ステップ１０１）。この結果、モードダイヤル４４が視線キャリブレーション（ＣＬＡ）モードに設定されていれば（ステップ１０２）、注視点のキャリブレーションを実行する（ステップ１２８）。この注視点のキャリブレーションについては後述する。そして、注視点のキャリブレーションが終了すると、カメラはレリーズ釦４１が押込まれてスイッチＳＷ１がＯＮされるまで待機する（ステップ１０４）。また、上記モードダイヤル４４が視線キャリブレーションモードに設定されておらず（ステップ１０２）、かつ、電源ロックモードに設定されていれば（ステップ１０３）、カメラの電源はＯＦＦされる（ステップ１２９）。一方、モードダイヤル４４が通常の撮影モードに設定されていれば、レリーズ釦４１が押込まれてスイッチＳＷ１がＯＮされるまで待機する（ステップ１０４）。レリーズ釦４１が押込まれスイッチＳＷ１がＯＮされたことを信号入力回路１０４を介して検知すると、ＣＰＵ１００は姿勢検知手段によってカメラの姿勢がどの状態になっているかを検知する（ステップ１０５）。なお、上記の姿勢検知手段は、ＣＰＵ１００，信号入力回路１０４，姿勢検知スイッチＳＷ−ＡＮＧ１，ＳＷ−ＡＮＧ２から構成され、ＣＰＵ１００は信号入力回路１０４を介して送信されてくる姿勢検知スイッチＳＷ−ＡＮＧ１，ＳＷ−ＡＮＧ２の信号を分析してカメラの姿勢が横位置か、あるいは縦位置か判断する。次にＣＰＵ１００は視線検出を行う際に複数あるキャリブレーションデータの中のどのキャリブレーションデータを使用するかを示したキャリブレーションデータナンバーをＥＥＰＲＯＭ１００ａにて確認する。この時、確認したキャリブレーションデータナンバーが視線入力禁止モードに設定されていたら（ステップ１０６）、視線検出動作は行わずに直ちに各測距点に対する焦点検出を実行する（ステップ１１５）。一方、前記キャリブレーションデータナンバーが視線入力モードに対応した値に設定されていると（ステップ１０６）、該キャリブレーションデータナンバーに対応したキャリブレーションデータをＥＥＰＲＯＭ１００ａの所定のアドレス上から読み出す（ステップ１０７）。キャリブレーションデータの中には撮影者が眼鏡を装着しているか否かの情報も含まれており、該キャリブレーションデータより撮影者が眼鏡を装着していないと判定すると（ステップ１０８）、視線検出を実行するために裸眼撮影者用の照明を設定する（ステップ１１０）。例えば、カメラの姿勢が水平状態（横位置状態）であれば、ＩＲＥＤ駆動回路１０７を介してＩＲＥＤ１３ａ，１３ｂを選択して点灯させる。また、キャリブレーションデータより撮影者が眼鏡を装着していると判定すると（ステップ１０８）、ＣＰＵ１００は前記キャリブレーションデータナンバーに対応したＥＥＰＲＯＭ１００ａの所定のアドレス上に記憶された、撮影者が装着している眼鏡のレンズ情報を読み出す（ステップ１０９）。ここでいう眼鏡のレンズ情報とは、眼鏡レンズの曲率半径である。なお、この情報は後述のキャリブレーション動作によって、予めＥＥＰＲＯＭ１００ａ内に記憶されている。眼鏡レンズ情報を読み出すと、視線検出を実行するために裸眼撮影者用の照明を設定する（ステップ１１０）。例えば、カメラの姿勢が水平状態であれば、前述した様に、ＩＲＥＤ駆動回路１０７を介してＩＲＥＤ１３ｃ，１３ｂを選択して点灯させる。撮影者の眼球１５への照明を設定すると（ステップ１１０）、ＣＰＵ１００は視線検出を実行する（ステップ１１１）。ここで、上記ステップ１１１における視線検出動作について、図７のフローチャートにより説明する。撮影者の眼球１５が照明手段により照明されると、眼球１５で反射した赤外光の一部は、受光手段である受光光学系を介してイメージセンサ１４上に集光する。このイメージセンサ１４からの画像出力はＣＣＤ読出し回路１０１においてＡ／Ｄ変換され、視線演算手段であるＣＰＵ１００にて画像解析される。ＣＰＵ１００は眼球１５の特徴点である角膜反射像と瞳孔の中心位置とを検出すると、前記（２），（３）式に基づいて撮影者の視線〔（θｘ，θｙ）：眼球の回転角〕を算出する（ステップ２００）。このとき、撮影者が眼鏡を装着していなければ（ステップ２０１）、メインのフローに復帰する（ステップ２０４）。一方、撮影者が眼鏡を装着していれば（ステップ２０１）、ＣＰＵ１００は画像解析した撮影者の眼球１５の特徴点の位置から、撮影者の眼球１５のカメラの基準位置、例えば接眼レンズ１１の射出面（撮影者側の面）の中心位置からの相対変位量を算出する。撮影者の眼球１５の角膜１６の曲率中心ｏのファインダ光軸からの変位を（ｓｘ，ｓｙ）とすると、    ｓｘ＝｛（ｘｐｏ−δｘ−ｘｓ）＊ｐｉｔｃｈ｝／β  …（６）    ｓｙ＝｛（ｙｐｏ−δｙ−ｙｓ）＊ｐｉｔｃｈ｝／β  …（７）となる。ここで、（ｘｓ，ｙｓ）はイメージセンサ１４の中心画素（受光光学系の光軸上の画素）である。撮影者の眼球１５の角膜１６の曲率中心ｏのファインダ光軸からの変位量〔＝ｓｑｒ（ｓｘ＾２＋ｓｙ＾２）〕が所定値、例えば 4.0より小さければ（ステップ２０２）、眼鏡レンズによる屈折作用の撮影は小さいため視線の補正を行わずにメインのルーチンに復帰する（ステップ２０４）。また、撮影者の眼球１５の角膜１６の曲率中心ｏのファインダ光軸からの変位量〔＝ｓｑｒ（ｓｘ＾２＋ｓｙ＾２）〕が所定値、例えば 4.0以上であれば（ステップ２０２）、先に記憶手段であるＥＥＰＲＯＭ１００ａより読み出した眼鏡レンズ情報から角膜反射像の位置とイメージセンサ１４の中心画素（ｘｓ，ｙｓ）の値を補正した後、前記（２），（３）式に基づいて撮影者の視線（θｘ，θｙ）を算出する（ステップ２０３）。撮影者の視線を補正して算出すると（ステップ２０３）、メインのルーチンに復帰しカメラのシーケンスを続行する（ステップ２０４）。図８は眼鏡レンズの屈折作用について説明する為の図であり、以下同図を用いて角膜反射像の位置の補正方法を説明する。同図において、撮影者の眼球１５は不図示のファインダ系光軸（図中のｚ軸と一致）に対して−ｘ方向に変位しており、また撮影者の眼球１５を照明するＩＲＥＤは１個のみ示している。ここで照明用ＩＲＥＤ１３ａは接眼レンズ１１射出面と同一面に配置されている。ＩＲＥＤ１３ａから放射された赤外光は、眼鏡レンズ１８によって屈折して撮影者の眼球１５を照明する。撮影者の眼球１５の角膜１６の曲率中心ｏに向う光線を図中実線で示す。眼鏡を装着した撮影者に対して角膜反射像の虚像は図中Ｐ０の位置（ｘ座標）に発生する。撮影者が眼鏡を装着していなければ角膜反射像の虚像の位置は図中Ｐ１の位置（図中の点線上）に発生するため、眼鏡を装着した撮影者が裸眼の撮影者と同等の視線検出精度を得るためには、眼鏡を装着した撮影者の角膜反射像の位置Ｐ０を裸眼の撮影者の角膜反射像の位置Ｐ１に補正しなければならない。不図示のイメージセンサ上に投影された各角膜反射像のｘ座標をｘｐ０，ｘｐ１とすると、それぞれは、    ｘｐ１＝ｘｐ０＋δｘｐ                …………（８）の関係式を満足する。ここで、δｘｐは眼鏡を装着した撮影者の角膜反射像の位置を補正する補正値で、その値は、    δｘｐ＝｛（２＊ｓｚ−Ｒｃ）／（２＊ｓｚ）｝                              ＊（ｓｘｉ−ｓｉ０）＊β／ｐｉｔｃｈとなる。ここで、ｓｚは角膜１６の曲率中心ｏのＩＲＥＤ１３ａ設置面からのｚ方向の距離、Ｒｃは角膜１６の曲率半径、ｓｘｉはＩＲＥＤ１３ａのファインダ光軸（ｚ軸）からのｘ方向の距離である。また、ｓｉ０は、眼鏡を装着した撮影者から見たＩＲＥＤ１３ａの見かけの位置Ｉ０のファインダ光軸（ｚ軸）からのｘ方向の距離である。ＩＲＥＤ１３ａの見かけの位置Ｉ０は、眼鏡のレンズ情報に基づいて撮影者の眼球１５に対してレンズを配置設定し、公知の光線トレースを行うことによって求められる。実際には、撮影者の眼球１５は２個のＩＲＥＤにて照明されるため、各々のＩＲＥＤに対する角膜反射像のｘ，ｙ方向の位置を補正を行う必要がある。イメージセンサ１４の中心画素（ｘｓ，ｙｓ）の補正も同様で、眼鏡レンズ情報に基づいてレンズを配置設定し、受光光学系の光軸が眼鏡レンズ１１によってどのように屈折するかを光線トレースしてイメージセンサ１４との交点を求め、それをイメージセンサ１４の中心画素と設定すればよい。角膜反射像の位置及びイメージセンサ１４の中心画素（ｘｓ，ｙｓ）の値が補正されると、前記（２），（３）式に基づいて視線が再度算出される。再び図６に戻って、視線検出が終了すると（ステップ１１１）、ＣＰＵ１００は算出した視線〔眼球の回転角（θｘ，θｙ）〕からファインダ内の注視点を算出する（ステップ１１２）。ファインダ内注視点の座標（ｘ，ｙ）は、前記（４），（５）式により算出される。撮影者が注視しているファインダ内注視点を算出すると（ステップ１１２）、その注視点座標から焦点検出を行う測距点の選択を行う（ステップ１１３）。測距点は注視点座標から最も近い測距点を選択することになる。さらに、ＣＰＵ１００は、ＬＥＤ駆動回路１０６に信号を送信して選択された測距点をファインダ内に表示する。撮影者がファインダ内にスーパーインポーズ表示された測距点を見て、その測距点が撮影者の意図したものと異なることを認識してレリーズ釦４１から手を離してスイッチＳＷ１をＯＦＦしたのを信号入力回路１０４を介して検知すると（ステップ１１４）、ＣＰＵ１００は信号入力回路１０４を介して再度モード確認を行って（ステップ１０１）、通常の撮影モードであればスイッチＳＷ１がＯＮされるまで待機する（ステップ１０４）。また、スーパーインポーズ表示された測距点を見て撮影者が引続きスイッチＳＷ１をＯＮし続けたならば（ステップ１１４）、次にＣＰＵ１００は自動焦点検出回路１０３により視線情報より選択された測距点の焦点検出を実行する（ステップ１１５）。そして、焦点検出が完了すると（ステップ１１５）、実際に撮影レンズ１の焦点調節を行う測距点を決定する（ステップ１１６）。このとき、カメラが視線入力禁止モードに設定されていたら、焦点検出を行った全測距点の中から物体距離が最も短い測距点を、実際に撮影レンズ１の焦点調節を行う測距点を決定する。次に、視線情報によって決定した測距点が測距不能であるか否かを確認し（ステップ１１７）、もし測距不能の場合はＣＰＵ１００はＬＣＤ駆動回路１０５に信号を送ってファインダ内ＬＣＤ２４の合焦マーク５０を点滅させ、測距がＮＧ（不能）であることを撮影者に警告する（ステップ１２５）。該警告表示はスイッチＳＷ１が離されるまで継続する（ステップ１２６）。また、決定した測距点が測距可能であり（ステップ１１７）、該測距点に対応する撮影レンズ１の焦点調節状態が合焦していなければ（ステップ１１８）、ＣＰＵ１００はレンズ焦点調節回路１１０に信号を送って撮影レンズ１の合焦レンズ１ａを所定量駆動させる（ステップ１２７）。レンズ駆動後に自動焦点検出回路１０３を介して決定している１つの測距点の焦点検出を再度行い（ステップ１１５）、撮影レンズ１が合焦しているか否かの判定を行う（ステップ１１８）。撮影レンズが合焦していたならば（ステップ１１８）、ＣＰＵ１００はＬＣＤ駆動回路１０５に信号を送ってファインダ内ＬＣＤ２４の合焦マーク５０を点灯させると共に、ＬＥＤ駆動回路１０６にも信号を送って合焦している測距点に合焦表示させる（ステップ１１９）。このとき、前記視線によって選択された測距点の点滅表示は消灯し、合焦したことを撮影者に認識させるために合焦測距点は点灯状態に設定する。合焦した測距点がファインダ内に表示されたのを撮影者が見て、その測距点が正しくないと認識してレリーズ釦４１から手を離しスイッチＳＷ１をＯＦＦすると（ステップ１２０）、ＣＰＵ１００は再度モード確認を行って（ステップ１０１）、通常の撮影モードであればスイッチＳＷ１がＯＮされるまで待機する（ステップ１０４）。また、撮影者が合焦表示された測距点を見て、引続きスイッチＳＷ１をＯＮし続けたならば（ステップ１２０）、ＣＰＵ１００は測光回路１０２に信号を送信して測光を行わせる（ステップ１２１）。このとき合焦した測距点を含む測光領域２１０〜２１３に重み付けを行った露出値を演算する。さらに、レリーズ釦４１が押込まれてスイッチＳＷ２がＯＮされているかどうかの判定を行い（ステップ１２２）、スイッチＳＷ２がＯＦＦ状態であれば、再びスイッチＳＷ１の状態の確認を行う（ステップ１２０）。また、スイッチＳＷ２がＯＮされたならば、ＣＰＵ１００はシャッタ制御回路１０８，モータ制御回路１０９，絞り駆動回路１１１にそれぞれ信号を送信して、以下のシャッタレリーズ動作を開始する。つまり、先ずモータＭ２に通電し、主ミラー２をアップさせ、絞り３１を絞り込んだ後、マグネットＭＧ１に通電しシャッタ４の先幕を開放する。絞り３１の絞り値及びシャッタ４のシャッタスピードは、前記測光回路１０２にて検知された露出値とフィルム５の感度から決定される。所定のシャッタ秒時経過後マグネットＭＧ２に通電し、シャッタ４の後幕を閉じる（ステップ１２３）。フィルム５への露光が終了すると、モータＭ２に再度通電し、ミラーダウン，シャッタチャージを行うとともにモータＭ１にも通電し、フィルムの駒送りを行い、一連のシャッタレリーズの動作が終了する（ステップ１２４）。カメラのシャッタレリーズ及び給送動作が終了すると（ステップ１２４）、ＣＰＵ１００は再度モード確認を行って（ステップ１０１）、通常の撮影モードであればスイッチＳＷ１がＯＮされるまで待機する（ステップ１０４）。図９は、図６のステップ１２８において実行される注視点のキャリブレーション動作を示すフローチャートであり、以下同図を用いて説明する。撮影者がモードダイヤル４４を回転させ、「ＣＡＬ」ポジション４４ｄを指標５５に合せると、視線キャリブレーションモードが設定される（ステップ１２８）。視線キャリブレーションモードは、キャリブレーション動作を行う「ＯＮ」モードとキャリブレーション動作を行わない「ＯＦＦ」モードとがある。各モードは電子ダイヤル４５を回転させることによって選択できる。「ＯＮ」モードにおいては、例えば５つのキャリブレーションナンバー（ＣＡＬ１〜ＣＡＬ５）が選択可能で、ＥＥＰＲＯＭ１００ａには選択されたキャリブレーションナンバーに対応したアドレス上にキャリブレーションデータが５組記憶可能となっている。また、この時選択されたキャリブレーションナンバーはキャリブレーションデータナンバー（１〜５）としてＥＥＰＲＯＭ１００ａに記憶される。また、電子ダイヤル４５によって「ＯＦＦ」モードを選択すると、ＥＥＰＲＯＭ１００ａに記憶されるキャリブレーションデータナンバーが例えば「０」に設定され、視線入力禁止モードに設定される。ＣＰＵ１００はＬＣＤ駆動回路１０５に信号を送信し、ファインダ内ＬＣＤ２４及びモニタ用ＬＣＤ４２に視線キャリブレーションモードに入ったことを示す表示を行う（ステップ３０１）。撮影者がファインダ内ＬＣＤ２４あるいはモニタ用ＬＣＤ４２に表示されたキャリブレーションナンバーを見ながら所望のキャリブレーションナンバーを選択したら、ＣＰＵ１００は選択されたキャリブレーションナンバーを確認する（ステップ３０２）。そして、確認したキャリブレーションナンバーはキャリブレーションデータナンバーとしてＥＥＰＲＯＭ１００ａの所定のアドレス上に記憶する。続いてＣＰＵ１００は信号入力回路１０４を介して撮影モードの確認を行う（ステップ３０３）。撮影者がモードダイヤル４４を回転させて注視点のキャリブレーションモード以外の撮影モードに切換えていることを確認したら（ステップ３０３）、モード変更がなされたとしてファインダ内外のキャリブレーション用表示を消灯させて（ステップ３０４）、メインのルーチンであるカメラの撮影動作に復帰する（ステップ３２７）。このとき、キャリブレーションナンバー「ＣＡＬ１〜ＣＡＬ５」が表示されている状態でモードダイヤル４４を他の撮影モードに切換えれば、そのキャリブレーションナンバーのキャリブレーションデータを用いて視線検出を行い、前述の視線情報を用いた撮影動作が行えるようになっている。一方、視線キャリブレーションモードに設定されたままであることを確認すると（ステップ３０３）、電子ダイヤル４５にて設定されたキャリブレーションナンバーの確認を再度行う（ステップ３０５）。このとき、ＥＥＰＲＯＭ１００ａに記憶されたキャリブレーションデータナンバーが「０」に設定され視線入力禁止モードが選択されていれば（ステップ３０５）、再度キャリブレーションナンバーの確認を行い（ステップ３０２）、撮影モードが変更されるまで待機する（ステップ３０３）。則ち、ファインダ内ＬＣＤ２４及びモニタ用ＬＣＤ４２に「ＯＦＦ」が表示されている状態でモードダイヤル４４を切換えれば、視線検出を行わないで撮影動作を行うようになっている。キャリブレーションデータナンバーが「０」以外の値に設定されていれば（ステップ３０５）、次に姿勢検知手段によってカメラの姿勢を検知する（ステップ３０６）。前述した様に、姿勢検知手段は信号入力回路１０４を介して姿勢検知スイッチＳＷ−ＡＮＧ１，ＳＷ−ＡＮＧ２であるところの水銀スイッチ２７及び不図示の水銀スイッチの出力信号を処理して、カメラが横位置であるか縦位置であるか、また縦位置である場合はレリーズ釦４１が天方向（上方向）にあるか地方向（下方向）にあるかを判断する。注視点のキャリブレーションは、スイッチＳＷ１をＯＮする事により開始されるように設定されている。撮影者が、注視点のキャリブレーションを行う準備が整う以前にカメラ側がキャリブレーションを開始するのを防ぐために、ＣＰＵ１００はスイッチＳＷ１の状態の確認を行い、スイッチＳＷ１がレリーズ釦４１によって押されていてＯＮ状態であればスイッチＳＷ１がＯＦＦ状態になるまで待機する（ステップ３０７）。その後、ＣＰＵ１００は信号入力回路１０４を介してスイッチＳＷ１がＯＦＦ状態であることを確認すると（ステップ３０７）、ＬＥＤ駆動回路１０６に信号を送信して注視点のキャリブレーション用視標１を点滅させる（ステップ３０８）。注視点のキャリブレーション用視標は測距点マーク２００，２０４と兼用しており、ファインダ内にスーパーインポーズ表示される。また、キャリブレーションを実行する際に最初に提示される第１の視標は、カメラの姿勢によって選択される。カメラの姿勢が横位置の状態では、キャリブレーション用視標は左端の測距点２００から点滅を開始する。また、カメラの姿勢がレリーズ釦４１が天方向にある第１の縦位置の状態であれば、キャリブレーション用視標は撮影者に対して下端の測距点２００から点滅を開始する。同様に、カメラの姿勢がレリーズ釦４１が地方向にある第２の縦位置の状態であれば、キャリブレーション用視標は撮影者に対して下端の測距点２０４から点滅を開始する。注視点のキャリブレーションの開始のトリガ信号であるスイッチＳＷ１のＯＮ信号が入っていなければ待機する（ステップ３０９）。点滅を開始した視標を撮影者が注視しレリーズ釦４１を押してスイッチＳＷ１をＯＮしたら（ステップ３０９）、ＣＰＵ１００はＬＥＤ駆動回路１０６に信号を送信してキャリブレーション用視標１を点灯させる（ステップ３１０）。さらにＣＰＵ１００は、ＩＲＥＤ駆動回路１０７に信号を送信して撮影者の眼球１５を照明するＩＲＥＤを点灯させる。このとき、ＩＲＥＤ駆動回路１０７を介して裸眼撮影者用のＩＲＥＤ１３ａ，１３ｂ，１３ｅ，１３ｆを選択して点灯させるが、これは撮影者が眼鏡を装着しているか否かを判定しやすくするためである。すなわち、裸眼撮影者用のＩＲＥＤが点灯すると、撮影者が眼鏡を装着していれば該眼鏡レンズ１８で反射する照明光の一部が受光光学系に入射しやすくなり、イメージセンサ１４上にゴーストとして像を形成する。ＣＣＤ読出し回路１０１はイメージセンサ１４で得られた像信号をＡ／Ｄ変換してＣＰＵ１００に送信し、さらにＣＰＵ１００は得られた眼球像信号を解析して撮影者が眼鏡を装着しているか否かを判定する（ステップ３１１）。このとき、撮影者が眼鏡を装着しているか否かを検知できればよいので、上述の裸眼照明による眼球像を得る際は、ＩＲＥＤの照明光量を小さくしたり、ＩＲＥＤの照明と同期したイメージセンサ１４の蓄積時間を短くして、消費電力を小さくするのは有効である。撮影者が眼鏡を装着していないと判定したら（ステップ３１２）、視線検出を実行するための照明用ＩＲＥＤを設定する（ステップ３１４）。一方、撮影者が眼鏡を装着していると判定したら（ステップ３１２）、先に検出した眼球像信号から眼鏡レンズ情報、すなわち眼鏡レンズ１８の曲率半径を算出する。眼鏡レンズ情報検出手段であるところのＣＰＵ１００は、眼球像信号より眼鏡があることにより発生したゴーストの位置を検出する。ゴーストの光強度は強いので、所定のしきい値を設けてそれを超える像をゴーストと判定してその重心を計算すればよい。また、眼鏡には照明光が反射するレンズ面が２面あるが、各レンズ面の位置及び曲率半径が異なるので各レンズ面によって形成されるゴーストの位置と大きさも異なってくる。この位置と大きさを比較することにより、どのレンズ面で反射した光によるゴーストかを判定することが可能である。ゴーストの位置が検出されると、眼鏡レンズ１８の曲率半径Ｒｇは、    Ｒｇ＝−〔（２＊△ｘｇ＊ｓ１＊ｓ２）                  ／｛△ｘｇ＊（ｓ１＋ｓ２）−２＊ｓｘｉ＊ｓ３｝〕                                                        …………（９）と求まる。ここで、各パラメータは、△ｘｇ：４個のＩＲＥＤにて形成される眼鏡レンズ１８によるゴーストのイメージセンサ上でのｘ方向の間隔（単位）ｓ１  ：受光光学系の前側主点から眼鏡のレンズ面までの距離（単位）ｓ２  ：ＩＲＥＤ配置面（接眼レンズ射出面）から眼鏡のレンズ面までの距離（単位）ｓ３  ：受光光学系の後側主点からイメージセンサ１４チップ面までの距離（単位）である。眼鏡レンズ１８の第１のレンズ面と第２のレンズ面とでは曲率半径が異なるため、イメージセンサ１４上に形成されるゴーストも異なる位置に発生する。その結果、第１のレンズ面で反射した光によるイメージセンサ１４上でのゴーストの間隔と、第２のレンズ面で反射した光によるイメージセンサ１４上でのゴーストの間隔とは異なるため、それぞれの値を上記（９）式に代入することによって各レンズ面の曲率半径を算出する。このとき、第１のレンズ面と第２のレンズ面とはレンズの厚さ分位置が異なるので、上記パラメータｓ１，ｓ２を修正して曲率半径を算出するのは言うまでもない。眼鏡レンズ情報（眼鏡レンズの曲率半径）を検出すると、その情報を記憶手段であるＥＥＰＲＯＭ１００ａの現在設定されたキャリブレーションナンバーに対応した所定のアドレス上にメモリする（ステップ３１３）。このとき、既に眼鏡レンズ情報がＥＥＰＲＯＭ１００ａにメモリされていたら、新に検出された眼鏡レンズ情報を既に記憶されていた眼球レンズ情報に加重平均した値にしてメモリする。眼鏡レンズ情報を検出し記憶手段にメモリすると（ステップ３１３）、視線検出を実行するための照明用ＩＲＥＤを設定する（ステップ３１４）。照明用ＩＲＥＤは撮影者の眼球１５を下方から照明するようにＩＲＥＤ駆動回路１０７によって選択される。つまり、姿勢検知手段によって検知されたカメラの姿勢が横位置の状態であれば、ＩＲＥＤ１３ａ，１３ｂを選択する。また、撮影者が眼鏡装着者の場合は、ＩＲＥＤ１３ｃ，１３ｄを選択する。一方、カメラの姿勢がレリーズ釦４１が天方向にある第１の縦位置の状態であれば、ＩＲＥＤ１３ａ，１３ｅを選択し、眼鏡装着者に対しては、ＩＲＥＤ１３ｃ，１３ｇを選択する。また、カメラの姿勢がレリーズ釦４１が地方向にある第２の縦位置の状態であれば、ＩＲＥＤ１３ｂ，１３ｆを選択し、眼鏡装着者に対しては、１３ｄ，１３ｈを選択する。照明用ＩＲＥＤを設定すると（ステップ３１４）、視線検出を実行する（ステップ３１５）。１回の視線検出が終了する毎に視線検出回数を加算する。視線検出のフローは、図７に示した通りである。視線検出が終了すると（ステップ３１５）、視線検出回数を確認する。注視点のキャリブレーションデータを求めるのに十分な所定の視線検出回数に達していなければ（ステップ３１６）、視線検出を続行する（ステップ３１５）。また、注視点のキャリブレーションデータを求めるのに十分な所定の視線検出回数に達していれば（ステップ３１６）、現在表示している視標に対する視線検出を終了する。ＣＰＵ１００は、視線検出が終了したことを撮影者に認識させるために、図示されていない発音体を用いて電子音を数回鳴らさせる。同時にＣＰＵ１００は、ＬＥＤ駆動回路１０６を介して視標を消灯させる（ステップ３１７）。引続きＣＰＵ１００は、検出した複数の視線情報（θｘ，θｙ）及び瞳孔径Ｒｐのデータ処理を行う（ステップ３１８）。これは撮影者が視標を注視しているとき、本人の意志に反して視線が動いた時に検出したデータを除外する処理である。ＣＰＵ１００は検出データの平均値に対して偏差の大きいデータを除外して、残ったデータの平均値を算出する。さらにＣＰＵ１００は、データ処理した後のデータが有効であるかどうかの判定を行う（ステップ３１９）。判定は、複数の検出データのうち有効であったデータの数及びその平均値を基準値と比較して行われる。例えば、１０個の検出データに対して有効なデータ数が５以下であったりその平均値が所定の範囲を超えていた場合は、視標に対するキャリブレーションデータをとるのに失敗したと判定して（ステップ３１９）、ＣＰＵ１００は図示されていない発音体を用いて電子音を所定時間鳴らし、さらにＬＣＤ駆動回路１０５に信号を送信してファインダ内ＬＣＤ２４及びモニタ用ＬＣＤ４２において「ＣＡＬ」表示を点滅させて撮影者に警告する（ステップ３２６）。一方、有効なデータ数が５より多く、かつ、その平均値が所定の範囲内であった場合は、データ処理後データは有効であると判定して（ステップ３１９）、さらに注視点のキャリブレーションが終了したか否かを判定する（ステップ３２０）。第２の視標に対するキャリブレーションが終了していない場合は（ステップ３２０）、第２の視標に対する視線検出を開始する（ステップ３０７）。以下の動作は上述の通りである。第２の視標に対するキャリブレーションが終了したならば（ステップ３２０）、ＣＰＵ１００は処理データをＥＥＰＲＯＭ１００ａの所定のアドレス上に記憶する（ステップ３２１）。ＥＥＰＲＯＭ１００ａに記憶するキャリブレーションデータは、眼球の回転角の平均値、瞳孔径の平均値及びそれらの値の積であるが、キャリブレーションデータはキャリブレーション毎に更新はされずに既に記憶している値に対して加算されるようになっている。キャリブレーションデータとともにキャリブレーション回数のメモリが終了すると（ステップ３２１）、ＣＰＵ１００はＬＣＤ駆動回路１０５，ＬＥＤ駆動回路１０６を介して注視点のキャリブレーション終了表示を行う（ステップ３２２）。ＬＥＤ駆動回路１０６はスーパーインポーズ用ＬＥＤ２１に通電し二つの視標を数回点滅させるとともに、ＬＣＤ駆動回路１０５はＬＣＤ２４，４２に信号を送信して「ＥＮＤ」の表示を所定時間実行するようになっている。ところで、キャリブレーション終了表示後（ステップ３２２）、あるいは、キャリブレーションＮＧ表示後（ステップ３２６）、撮影者がスイッチＳＷ１をＯＮしたらＣＰＵ１００は信号入力回路１０４を介してスイッチＳＷ１のＯＮ信号を検知して（ステップ３２３）、再度注視点のキャリブレーションを実行できるように注視点キャリブレーションの開始のステップに移行する（ステップ３０６）。一連の注視点のキャリブレーション終了後、カメラは撮影者によって電子ダイヤル４５かモードダイヤル４４が操作されるまで待機する。撮影者が電子ダイヤル４５を回転させて他のキャリブレーションナンバーを選択したならば、ＣＰＵ１００は信号入力回路１０４を介してキャリブレーションナンバーの変更を検知して（ステップ３２４）、注視点のキャリブレーションルーチンの初期のステップ（３０１）に移行する。また、撮影者がモードダイヤル４４を回転させて他の撮影モードを選択したならば、ＣＰＵ１００は信号入力回路１０４を介して撮影モードの変更を検知して（ステップ３２５）、メインのルーチンに復帰する（ステップ３２７）。（第２の実施例）図１０は本発明の第２の実施例に係る視線検出機能を有したカメラの動作を示すフローチャートである。なお、本実施例のカメラは、図１〜図５に示したカメラの構成と同等であるため、以下各図を用いてカメラの動作を説明する。モードダイヤル４４を回転させてカメラを不作動状態（ロック状態）から所定の撮影モードに設定すると、カメラの電源がＯＮされる（ステップ１３０）。すると、ＣＰＵ１００は信号入力回路１０４を介してモードダイヤル４４がどのモードに設定されているかを確認する（ステップ１３１）。この結果、モードダイヤル４４が視線キャリブレーション（ＣＬＡ）モードに設定されていれば（ステップ１３２）、注視点のキャリブレーションを実行する（ステップ１５８）。この注視点のキャリブレーションについては後述する。そして、注視点のキャリブレーションが終了すると、カメラはレリーズ釦４１が押込まれてスイッチＳＷ１がＯＮされるまで待機する（ステップ１３４）。また、上記モードダイヤル４４が視線キャリブレーションモードに設定されておらず（ステップ１３２）、かつ、電源ロックモードに設定されていれば（ステップ１３３）、カメラの電源はＯＦＦされる（ステップ１５９）。一方、モードダイヤル４４が通常の撮影モードに設定されていれば、レリーズ釦４１が押込まれてスイッチＳＷ１がＯＮされるまで待機する（ステップ１３４）。レリーズ釦４１が押込まれスイッチＳＷ１がＯＮされたことを信号入力回路１０４を介して検知すると、ＣＰＵ１００は姿勢検知手段によってカメラの姿勢がどの状態になっているかを検知する（ステップ１３５）。次にＣＰＵ１００は視線検出を行う際に複数あるキャリブレーションデータの中のどのキャリブレーションデータを使用するかを示したキャリブレーションデータナンバーをＥＥＰＲＯＭ１００ａにて確認する。この時、確認したキャリブレーションデータナンバーが視線入力禁止モードに設定されていたら（ステップ１３６）、視線検出動作は行わずに直ちに各測距点に対する焦点検出を実行する（ステップ１４５）。一方、前記キャリブレーションデータナンバーが視線入力モードに対応した値に設定されていると（ステップ１３６）、該キャリブレーションデータナンバーに対応したキャリブレーションデータをＥＥＰＲＯＭ１００ａの所定のアドレス上から読み出す（ステップ１３７）。キャリブレーションデータの中には撮影者が眼鏡を装着しているか否かの情報と眼鏡装着者に対しては装着している眼鏡のレンズ情報（眼鏡レンズの曲率半径）も含まれている。該キャリブレーションデータより撮影者が眼鏡を装着していないと判定すると（ステップ１３８）、視線検出を実行するために裸眼撮影者用の照明を設定する（ステップ１４０）。また、読み出したキャリブレーションデータより撮影者が眼鏡を装着していると判定すると（ステップ１３８）、ＣＰＵ１００は眼鏡レンズ情報の検出を実行する（ステップ１３９）。ここで検出される眼鏡レンズ情報は、眼鏡レンズの曲率半径と曲率中心の値である。以下、眼鏡レンズ情報の検出方法を説明する。ＣＰＵ１００は、ＩＲＥＤ駆動回路１０７に信号を送信して裸眼撮影者用のＩＲＥＤ１３ａ，１３ｂ，１３ｅ，１３ｆを選択して点灯させる。ＣＣＤ読出し回路１０１はイメージセンサ１４で得られた像信号をＡ／Ｄ変換してＣＰＵ１００に送信し、さらにＣＰＵ１００は得られた眼球像信号を解析して眼鏡があることにより発生したゴーストの位置を検出する。ゴーストの光強度は強いので、所定のしきい値を設けてそれを超える像をゴーストと判定してその重心を計算すればよい。また、眼鏡には照明光が反射するレンズ面が２面あるが、各レンズ面の位置及び曲率半径が異なるので各レンズ面によって形成されるゴーストの位置と大きさも異なっている。この位置と大きさを比較することにより、どのレンズ面で反射した光によるゴーストかを判定することが可能である。ゴーストに位置を検出すると、眼鏡レンズ１８の曲率半径Ｒｇを上述の（９）式より算出する。同様に、眼鏡レンズ１８の曲率中心（ｓｘｇ，ｓｙｇ，ｓｚｇ）をゴーストの位置より、    ｓｘｇ＝〔｛２＊ｓ１＊ｓ２＋Ｒｇ＊（ｓ１＋ｓ２）｝                  ／（２＊ｓ２＊ｓ３）〕＊（ｘｇ０−ｘｓ）＊ｐｉｔｃｈ                                                      …………（１０）    ｓｙｇ＝｛（ｙｇ０−ｙｓ）／（ｘｇ０−ｘｓ）｝＊ｓｘｇ                    −（Ｒｇ＊ｓｙｉ）／（２＊ｓ２）  …………（１１）    ｓｚｇ＝ｓ２＋Ｒｇ                        …………（１２）と求める。ここで、（ｘｇ０，ｙｇ０）はイメージセンサ１４上に形成された４つのゴーストの中心位置（単位）、ｓｙｉは照明用ＩＲＥＤの受光光学系の光軸（ｚ軸）からの絶対距離（単位）、ｓ１，ｓ２，ｓ３は前述の通りである。眼鏡レンズ情報を検出すると（ステップ１３９）、視線検出を実行するために照明を設定する（ステップ１４０）。撮影者の眼球１５への照明を設定すると（ステップ１４０）、ＣＰＵ１００は視線検出を実行する（ステップ１４１）。視線検出のフローは図７と同様で、以下同図を用いて説明する。撮影者の眼球１５が照明手段により照明されると、眼球１５で反射した赤外光の一部は、受光手段である受光光学系を介してイメージセンサ１４上に集光する。イメージセンサ１４からの画像出力はＣＣＤ読出し回路１０１においてＡ／Ｄ変換され、視線演算手段であるＣＰＵ１００にて画像解析される。ＣＰＵ１００は眼球の特徴点である角膜反射像と瞳孔の中心位置とを検出すると、前記（２），（３）式に基づいて撮影者の視線〔（θｘ，θｙ）：眼球の回転角〕を算出する（ステップ２００）。このとき、イメージセンサ１４の中心画素（ｘｓ，ｙｓ）は初期値が使用される。さらに、撮影者が眼鏡を装着していなければ（ステップ２０１）、メインのフローに復帰する（ステップ２０４）。一方、撮影者が眼鏡を装着している場合には（ステップ２０１）、直前に検出した眼鏡レンズ情報から眼鏡レンズの頂点の、カメラの基準位置、例えば接眼レンズ１１の射出面（撮影者側の面）の中心位置からの相対変位量を算出する。眼鏡レンズの第１面の頂点のファインダ光軸からの変位を（ｓｇｘ，ｓｇｙ）とすると、    ｓｇｘ＝｛（ｓ２−ｓｚｇ１）／（ｓｚｇ１−ｓｚｇ２）｝                    ＊（ｓｘｇ１−ｓｘｇ２）＋ｓｘｇ１  ………（１４）    ｓｇｙ＝｛（ｓ２−ｓｚｇ１）／（ｓｚｇ１−ｓｚｇ２）｝                    ＊（ｓｙｇ１−ｓｙｇ２）＋ｓｙｇ１  ………（１５）となる。ここで、（ｓｘｇ１，ｓｙｇ１，ｓｚｇ１），（ｓｘｇ２，ｓｙｇ２，ｓｚｇ２）は眼鏡レンズの第１面と第２面の曲率中心位置である。眼鏡レンズ第１面頂点のファインダ光軸からの変位量〔＝ｓｑｒ（ｓｇｘ＾２＋ｓｇｙ＾２）〕が所定値、例えば 4.0より小さければ（ステップ２０２）、眼鏡レンズによる屈折作用の影響は小さいため視線の補正を行わずにメインのルーチンに復帰する（ステップ２０４）。また、眼鏡レンズ第１面頂点のファインダ光軸からの変位量〔＝ｓｑｒ（ｓｇｘ＾２＋ｓｇｙ＾２）〕が所定値、例えば 4.0以上であれば（ステップ２０２）、検出した眼鏡レンズ情報から角膜反射像の位置とイメージセンサ１４の中心画素（ｘｓ，ｙｓ）の値を補正した後、前記（２），（３）式に基づいて撮影者の視線（θｘ，θｙ）を算出する（ステップ２０３）。角膜反射像の位置とイメージセンサ１４の中心画素（ｘｓ，ｙｓ）の補正方法は前述の通りである。撮影者の視線を補正して算出すると（ステップ２０３）、メインのルーチンに復帰しカメラのシーケンスを続行する（ステップ２０４）。再び図１０に戻って、視線検出が終了すると（ステップ１４１）、ＣＰＵ１００は算出した視線〔眼球の回転角（θｘ，θｙ）〕からファインダ内の注視点を算出する（ステップ１４２）。ファインダ内注視点の座標（ｘ，ｙ）は、前記（４），（５）式により算出される。撮影者が注視しているファインダ内注視点を算出すると（ステップ１４２）、その注視点座標から焦点検出を行う測距点の選択を行う（ステップ１４３）。測距点は注視点座標から最も近い測距点を選択することになる。さらに、ＣＰＵ１００は、ＬＥＤ駆動回路１０６に信号を送信して選択された測距点をファインダ内に表示する。撮影者がファインダ内にスーパーインポーズ表示された測距点を見て、その測距点が撮影者の意図したものと異なることを認識してレリーズ釦４１から手を離してスイッチＳＷ１をＯＦＦしたのを信号入力回路１０４を介して検知すると（ステップ１４４）、ＣＰＵ１００は信号入力回路１０４を介して再度モード確認を行って（ステップ１３１）、通常の撮影モードであればスイッチＳＷ１がＯＮされるまで待機する（ステップ１３４）。また、スーパーインポーズ表示された測距点を見て撮影者が引続きスイッチＳＷ１をＯＮし続けたならば（ステップ１４４）、次にＣＰＵ１００は自動焦点検出回路１０３により視線情報より選択された測距点の焦点検出を実行する（ステップ１４５）。そして、焦点検出が完了すると（ステップ１４５）、実際に撮影レンズ１の焦点調節を行う測距点を決定する（ステップ１４６）。このとき、カメラが視線入力禁止モードに設定されていたら、焦点検出を行った全測距点の中から物体距離が最も短い測距点を、実際に撮影レンズ１の焦点調節を行う測距点を決定する。次に、視線情報によって決定した測距点が測距不能であるか否かを確認し（ステップ１４７）、もし測距不能の場合はＣＰＵ１００はＬＣＤ駆動回路１０５に信号を送ってファインダ内ＬＣＤ２４の合焦マーク５０を点滅させ、測距がＮＧ（不能）であることを撮影者に警告する（ステップ１５６）。該警告表示はスイッチＳＷ１が離されるまで継続する（ステップ１５７）。また、決定した測距点が測距可能であり（ステップ１４７）、該測距点に対応する撮影レンズ１の焦点調節状態が合焦していなければ（ステップ１４８）、ＣＰＵ１００はレンズ焦点調節回路１１０に信号を送って撮影レンズ１の合焦レンズ１ａを所定量駆動させる（ステップ１５５）。レンズ駆動後に自動焦点検出回路１０３を介して決定している１つの測距点の焦点検出を再度行い（ステップ１４５）、撮影レンズ１が合焦しているか否かの判定を行う（ステップ１４８）。撮影レンズが合焦していたならば（ステップ１４８）、ＣＰＵ１００はＬＣＤ駆動回路１０５に信号を送ってファインダ内ＬＣＤ２４の合焦マーク５０を点灯させると共に、ＬＥＤ駆動回路１０６にも信号を送って合焦している測距点に合焦表示させる（ステップ１４９）。このとき、前記視線によって選択された測距点の点滅表示は消灯し、合焦したことを撮影者に認識させるために合焦測距点は点灯状態に設定する。合焦した測距点がファインダ内に表示されたのを撮影者が見て、その測距点が正しくないと認識してレリーズ釦４１から手を離しスイッチＳＷ１をＯＦＦすると（ステップ１５０）、ＣＰＵ１００は再度モード確認を行って（ステップ１３１）、通常の撮影モードであればスイッチＳＷ１がＯＮされるまで待機する（ステップ１３４）。また、撮影者が合焦表示された測距点を見て、引続きスイッチＳＷ１をＯＮし続けたならば（ステップ１５０）、ＣＰＵ１００は測光回路１０２に信号を送信して測光を行わせる（ステップ１５１）。このとき合焦した測距点を含む測光領域２１０〜２１３に重み付けを行った露出値を演算する。さらに、レリーズ釦４１が押込まれてスイッチＳＷ２がＯＮされているかどうかの判定を行い（ステップ１５２）、スイッチＳＷ２がＯＦＦ状態であれば、再びスイッチＳＷ１の状態の確認を行う（ステップ１５０）。また、スイッチＳＷ２がＯＮされたならば、ＣＰＵ１００はシャッタ制御回路１０８，モータ制御回路１０９，絞り駆動回路１１１にそれぞれ信号を送信して、以下のシャッタレリーズ動作を開始する。つまり、先ずモータＭ２に通電し、主ミラー２をアップさせ、絞り３１を絞り込んだ後、マグネットＭＧ１に通電しシャッタ４の先幕を開放する。絞り３１の絞り値及びシャッタ４のシャッタスピードは、前記測光回路１０２にて検知された露出値とフィルム５の感度から決定される。所定のシャッタ秒時経過後マグネットＭＧ２に通電し、シャッタ４の後幕を閉じる（ステップ１５３）。フィルム５への露光が終了すると、モータＭ２に再度通電し、ミラーダウン，シャッタチャージを行うとともにモータＭ１にも通電し、フィルムの駒送りを行い、一連のシャッタレリーズの動作が終了する（ステップ１５４）。カメラのシャッタレリーズ及び給送動作が終了すると（ステップ１５４）、ＣＰＵ１００は再度モード確認を行って（ステップ１３１）、通常の撮影モードであればスイッチＳＷ１がＯＮされるまで待機する（ステップ１３４）。以上の各実施例によれば、眼球像の解析することにより観察者が眼鏡を装着しているか否かを検知し、観察者が眼鏡を装着していれば、前記眼球像中のゴーストの重心より眼鏡の曲率半径、つまり眼鏡のレンズ情報を検出し、この眼鏡レンズ情報に基づいて観察者の視線を補正演算するようにしているため、精度の高い視線検出が達成でできるとともに、裸眼の観察者に対しても眼鏡を装着した観察者に対しても同等の視線入力機能を提供できる効果がある。（発明と実施例の対応）本実施例において、イメージセンサ１４，受光レンズ１２，ＣＣＤ読出し回路１０１が本発明の受光手段に相当し、ＣＰＵ１００が本発明の視線検出手段、眼鏡レンズ情報検出手段に相当し、ＥＥＰＲＯＭ１００ａが記憶手段に相当し、ＩＲＥＤ１３ａ，１３ｂ，１３ｅ，１３ｆが裸眼観察者用の、１３ｃ，１３ｄ，１３ｇ，１３ｈが眼鏡観察者用の本発明の照明手段に相当する。以上が実施例の各構成と本発明の各構成の対応関係であるが、本発明は、これら実施例の構成に限定されるものではなく、請求項で示した機能、又は実施例がもつ機能が達成できる構成であればどのようなものであってもよいことは言うまでもない。（変形例）本実施例では裸眼観察用の光源と眼鏡観察者用の光源をそれぞれ４個備えた場合を例示しているが、少なくとも２個づつ備えていれば良い。この場合は、眼鏡レンズ情報検出時には、眼鏡観察者用と裸眼観察者用のそれぞれを用いることになる。勿論、眼鏡レンズ情報検出時には、裸眼観察者用の光源を３個以上備え、該光源のみを用いる方が精度の良い眼鏡レンズ情報を検出することができることは言うまでもない。また、第１の実施例では、眼鏡を装着している観察者に対する補正（眼球像の歪む補正）は、眼鏡レンズの曲率半径のみを用いる用にしているが、曲率中心位置の情報をも用いる方がより好ましいものである。一方、第２の実施例では、眼鏡を装着している観察者に対する補正は、眼鏡レンズの曲率半径と曲率中心位置の両方を用いるようにしているが、少なくとも曲率半径を用いても、従来に比べてはるかに適正な視線入力位置の検出が可能となる。又、本実施例では、眼鏡レンズ情報は演算により算出するようにしているが、これに限定されるものではなく、例えば外部より眼鏡レンズ情報（曲率半径や曲率中心位置）を入力し、これにより視線を補正するような構成のものであっても良い。本発明は、一眼レフカメラ，レンズシャッタカメラ，ビデオカメラ等のカメラに適用した場合を述べているが、その他の光学機器や他の装置、更には構成ユニットとしても適用することができるものである。更に、本発明は、以上の各実施例、又はそれらの技術を適当に組み合わせた構成にしてもよい。以上説明したように、請求項１又は１５記載の本発明によれば、眼鏡のレンズ情報を検出する眼鏡レンズ情報検出手段と、検出された眼鏡レンズ情報を記憶する記憶手段と、観察者が眼鏡を装着している場合は、受光手段にて得られた眼球像データと前記記憶手段に記憶された眼鏡レンズ情報から観察者の視線を演算する視線演算手段を備え、一度眼鏡レンズ情報を検出した後は記憶手段に記憶しておき、必要に応じて前記記憶手段より眼鏡レンズ情報を読出し、該眼鏡レンズ情報と受光手段にて得られた眼球像データとから、観察者の視線を算出するようにしている。また、請求項８又は１５記載の本発明によれば、観察者が眼鏡を装着している場合は、眼鏡のレンズ情報を検出する眼鏡レンズ情報検出手段と、観察者が眼鏡を装着している場合は、受光手段にて得られた眼球像データと前記眼鏡レンズ情報検出手段にて得られた眼鏡レンズ情報から観察者の視線を検出する視線検出手段とを備え、観察者が眼鏡を装着している場合は、毎回眼鏡レンズ情報を検出し、検出した眼鏡レンズ情報と受光手段にて得られた眼球像データとから、観察者の視線を検出するようにしている。また、請求項１４又は１５記載の本発明は、観察者が眼鏡を装着している場合は、眼鏡レンズの曲率半径を用いて、受光手段にて得られた眼球像データの歪を補正して視線を検出する視線検出手段とを備え、観察者が眼鏡を装着している場合は、受光手段にて得られた眼球像データを、眼鏡レンズの曲率半径により補正するようにしている。よって、視線入力精度を高めることができ、しかも、裸眼の観察者と眼鏡を装着した観察者の何れに対して、同等の視線入力を可能にすることができる。本発明の第１の実施例に係るカメラの要部を示す構成図である。図１のカメラの上面及び背面を示す図である。図１のカメラのファインダ視野内を示す図である。図２に示すモードダイヤルの上面図である。図１のカメラの電気的構成を示すブロック図である。本発明の第１の実施例におけるカメラの動作を示すフローチャートである。図６のステップ１１１にて実行される視線検出動作を示すフローチャートである。カメラを覗く使用者が眼鏡装着者であった場合について説明する為の図である。図６のステップ１２８にて実行される視線キャリブレーション動作を示すフローチャートである。本発明の第２の実施例におけるカメラの動作を示すフローチャートである。一般的な視線検出原理について説明する為の図である。眼球像と該眼球像を光電変換した際の出力強度分布について説明する為の図である。１１              接眼レンズ１２              受光レンズ１３ａ〜１３ｈ    ＩＲＥＤ１４              イメージセンサ１８              眼鏡レンズ１００            ＣＰＵ１００ａ          ＥＥＰＲＯＭ１０１            ＣＣＤ読出し回路１０４            信号入力回路１０６            ＩＲＥＤ駆動回路
